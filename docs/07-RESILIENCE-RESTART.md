# Resilience и повторный запуск

**Навигация:** [README](../README.md) | [Меню](00-INDEX.md) | [← Назад](06-OBSERVABILITY.md) | [Далее →](08-IMPLEMENTATION-ROADMAP.md)

---

## Зачем

Синк из соцсетей — долгий процесс (часы, дни). Сеть рвётся, API лимитирует, воркеры падают. Без продуманной стратегии:

- при сбое придётся начинать с нуля;
- повторный запуск может продублировать данные;
- непонятно, с какого места продолжать.

**Resilience** — это возможность безопасно перезапускать и докачивать данные: не терять прогресс, не дублировать, продолжать с места остановки.

---

## Идемпотентность шагов

**Проблема:** Повторный запуск шага не должен создавать дубликаты или ломать данные.

**Решение:** Каждый шаг получает детерминированные входы (batch_id, snapshot_id, S3 key) и пишет результат в однозначное место, например `etl/{batch_id}/stage3/`. При повторном запуске:

- если результат уже есть — шаг пропускается;
- если нет — выполняется и перезаписывает (с append-only и версионированием там, где это нужно).

Так один и тот же шаг можно запускать многократно без побочных эффектов.

---

## Снапшоты и версии

**Проблема:** Нужно уметь «откатиться» на предыдущее состояние данных или сравнить версии.

**Решение:**

- **Raw zone** — сырые данные не меняются после записи.
- **Transform/Load** — каждая обработка создаёт версию (partition version, snapshot).
- **lakeFS** или версионирование в DWH — для переключения на другую версию без поломки потребителей.

---

## Контрольные точки (checkpoints)

**Проблема:** При падении workflow непонятно, что уже сделано и с чего продолжать.

**Решение:** Явные этапы: **extracted** → **normalized** → **enriched** → **loaded**. Результаты каждого этапа сохраняются. При падении:

- рестарт workflow — шаги видят готовые артефакты и пропускают выполнение;
- или запуск нового workflow «from stage X» с повторным использованием артефактов прошлого запуска.

---

## Backfills

**Проблема:** Нужно пересинкать исторические данные за большой период.

**Решение:** Оркестратор создаёт множество runs (по датам, партициям), контролирует параллелизм и retries. Каждый run — отдельный workflow/job с собственными параметрами.

---

## Докачка для соцсетей (sync_jobs)

**Проблема:** Синк оборвался на середине (rate limit, таймаут, падение). Нужно продолжить, не начиная заново.

**Решение:**

- **Курсоры** (`since_id`, `updated_since`, page_token) хранятся в `sync_jobs.cursor`.
- **Рестарт:** создаётся новый `sync_job` со ссылкой на `previous_job`, копируются cursor и `last_synced_at`.
- **Шаги:** при повторном проходе проверяют `external_id` + network — если данные уже есть и актуальны, пропускают или делают upsert (если `changed_at` новее).
- **Большие объёмы (10M+ followers):** в БД хранятся границы страниц, чтобы рестартовать с нужной страницы.

Идея: любой шаг можно выполнить ещё раз — он либо ничего не меняет, либо только обновляет данные.
